\documentclass{article}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage[top=0.50in, bottom=0.50in, left=0.65in, right=0.75in]{geometry}
%\usepackage[a4paper, total={6in, 10in}]{geometry}
\usepackage[table]{xcolor}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage{mathtools}
\usepackage{amsmath,amssymb}
\usepackage[]{algpseudocode}
\usepackage{enumitem}
\title{CS345 Theoretical Assignment 5 \\ }
\author{\vspace{2mm} \large Ayush Agarwal, 13180 \\ M.Arunothia, 13378}
\date{}
\begin{document}
\maketitle
\tableofcontents

\newpage
\section{Binary search under insertion}
\subsection{Data Structure Overview}
The data structure consists of arrays of multiple arrays with size of the form $2^i$. For searching, we search each of these arrays. To insert an element,
we first insert it into the first array(of size 1). If it is full we try to insert them into array of size 2. If that is also full we try the same for array 
of size 4 and so on. This insertion operation is amortized $logn$.
\begin{itemize}
  \item \textbf{array}[i] is the pointer to array of size $2^i$
  \item \textbf{filled} number of arrays being used
\end{itemize}

\begin{algorithmic}[1]
\Procedure{\textbf{insertion}(int newElement)}{}
    \State i $\gets$ 0
    \While{!array[i].empty()}
    \State $i$++
    \EndWhile
    \State array[i] $\gets$ \textbf{merge}(array, i, newElement)
    \If{i $>=$ filled}
      \State filled $\gets$ i
    \EndIf
  \EndProcedure
  \\
  \Procedure{\textbf{merge}(int *array[], int end, int newElement)}{}
    \State Merge all the arrays with lengths starting from 1 to $2^end$ and insert the new element into that array.\\
    \State i $\gets$ 0
    \While{i $<$ end}
      \State free(array[i])
      \State $i$++
    \EndWhile
    \State return mergedArray
  \EndProcedure
  \\
  \Procedure{\textbf{search}(int element)}{}
    \State i $\gets$ 0
    \While{i $<=$ filled}
    \If {binarySearch(array[i], element)}
    \State return True
    \EndIf
    \State i $\gets$ i + 1
    \EndWhile
  \EndProcedure

\end{algorithmic}

\subsection{Justification}
At any point of time, any of the $array[i]$ will either be empty or completely filled. There can't be a case when any of the array is partially filled. Think of 
it like the binary number representation of number n. The indexes where n has value 1, those corresponding arrays are filled, rest are empty.

\subsection{Time Complexity Analysis}
\begin{itemize}
  \item \textbf{search} Worst case time would be when every array from size 1 to size $2^{logn-1}$ would be filled. Without the loss of generality assume n = $2^k$
    So search time,\\
    = log1 + log2 + $.....$ logn/2 \\
    = (1 + 2 + 3 $...$ k-1) \\
    = k(k-1)/2 \\
    = O($log^2$n) \\
    \\
  \item \textbf{insert}\\
    Let amortized function $$\phi(i) = \sum_{e}^{all elements}depth(e)  = \sum_{i}^{i \leq logn} 2^i(logn - i) $$ after the $i^th$ insertion where $depth(e) = logn - arrayIndex(e)$.\\
    \begin{tabular}{|p{4cm}|p{3cm}|p{3cm}|p{3cm}|  }
      \hline
      \multicolumn{4}{|c|}{Amortised Analysis} \\
      \hline
      Case & Actual Cost& $\Delta(\phi)$ & Amortised Cost\\
      \hline
      Direct Insert(no merge) & 1           & logn & O(logn)   \\
      On merge(till array $2^k$) & $2^{k+1}$   & $-\sum_{i}^{i<k} (2^i(k-i))$ & k+1 $\leq$ O(logn) \\
      \hline
    \end{tabular}

\end{itemize}

\newpage
\section{Binary search and predecessor/successor queries under deletions}
\subsection{Data Structure Overview}
The data structure proposed is an array $Z$ of size $|S|$. Each entry in the array has the following -
\begin{itemize}
\item Value $x$, where $x \in S$
\item Flag which is marked valid at the start. Invalid flag implies that entry has been deleted.
\item Index nextValid, that stores the next valid entry's index correctly for any valid entry.
\item Index prevValid, that stores the previous valid entry's index correctly for any valid entry.
\item For every index belonging to $\{logn,2logn,.. \}$, a boolean array of size $O(logn)$ is stored. The boolean array of $ith$ index will says whether there is any valid entry between i and each of  $\{i+1,i+2,i+4,i+8,..,i-1,i-2,i-4,i-8,..\}$. 
\end{itemize}
It can be easily seen that the data structure is $O(n)$. Apart from this we maintain global variables $Size$ and $DelCounter$. $Size$ tracks the size of the set $S$ whenever it is halved. $Size = n$ and $DelCounter = 0$ at the start.
\subsection{Search(x, Z): search for element x in S}
\subsubsection{Algorithm and Correctness}
The procedure is similar to a binary search with the only difference being that if the found entry is $invalid$, then we return $notFound$. The proof hence follows from the correctness of binary search. Note that we are given a set, implying there will be no repeating entries. This ensures that if at all an element existed in $S$, then our search will return its index correctly.
\subsubsection{Time Complexity Analysis}
Worst case - $O(log(n))$. Follows from the similarity with binary search.
\subsection{Predecessor(x, Z): report the largest elements in S which is smaller than x}
\subsubsection{Algorithm}
\begin{itemize}
\item We use binary search procedure to find the predecessor of $x$ in $S$. If the returned entry is $valid$, we are done. If not consider this returned index as $i$. 
\item Now we should find the $valid$ entry that is just before $i$. We first traverse linearly from $i$ to the first index of the form $klogn$, all the while checking for any valid entry. If valid entry found we are done. Otherwise, go to next step.
\item We use the boolean array of the $klogn$th entry to find $l$ such that the first valid entry before index $i$ lies in the range $(klogn-2^{l-1}, klogn-2^l)$
\item Let  us say that the first $valid$ entry actually lies at $klogn - m$. We have to find $m$. Look at the binary representation of $m$. It has $l-1$ digits. with first digit as $1$. Now each of the entry from left to right can be filled in $O(1)$ time by discarding half of the potential search space using the boolean arrays stored at the $jlogn$ indices.
\item return $klogn - m$  
\end{itemize}
\subsubsection{Time Complexity Analysis}
Worst case - $O(log(n))$. Each step mentioned in the algorithm is $O(logn)$
\newpage
\subsection{Delete(x, Z): Delete element x from S}
\subsubsection{Algorithm}
\begin{itemize}
\item We use binary search procedure to find the entry to be deleted, say it is $i$ 
\item If $DelCounter < Size/2$, we do the following
\begin{itemize}
\item Increment $DelCounter$
\item $i.flag = invalid$
\item $i.prevValid.nextValid = i.nextValid$
\item $i.nextValid.prevValid = i.prevValid$
\item For all entries of the form $jlogn$ between $i.prevValid$ and $i.nextValid$, we modify their boolean arrays accordingly so as to maintain the definition of these boolean values. (i.e)., if this was the last valid element in any range that has to be reflected in those boolean values.
\end{itemize}
\item Else
\begin{itemize}
\item Remove all invalid elements from the array and rebuilt the whole array that has now reduced to half its size.
\item $DelCounter = 0$
\item $Size = Size/2$ 
\end{itemize}
\end{itemize}
\subsubsection{Time Complexity Analysis}
We use amortised analysis to analyse the Time Complexity of the delete function. We define our potential function as \\
$\phi(X) = 2k * (X.Size) + $ Total number of $TRUE$ stored in the boolean arrays of the $jlogn$ indices. \\
Let $H(X) = $Number of boolean entries that has been turned $FALSE$ from being $TRUE$ in this turn.  \\
This implies that $\Delta(\phi)$ will be $0$ in the first case, as there is no change here and will be $2k * ((Size/2)-Size) = -k*Size$ in the second case. \\

\begin{tabular}{ |p{4cm}|p{4cm}|p{2cm}|p{3cm}|  }
 \hline
 \multicolumn{4}{|c|}{Amortised Analysis} \\
 \hline
 Case & Actual Cost& $\Delta(\phi)$ & Amortised Cost\\
 \hline
 $DelCounter < Size/2$ & clog(Size) + H(X)          & 0        & clog(Size)   \\
 $DelCounter = Size/2$ & clog(Size) + k*Size + H(X) & -k*Size  & clog(Size)  \\
 \hline
\end{tabular} \\

Hence, deletion is done in amortised $logn$.
\newpage    
\section{Extension of the problem of the mid-semester exam}
\subsection{Pseudo Code}
\begin{algorithmic}[1]
  \Procedure{\textbf{findSubgraph}(V,E)}{}
  \State $E_s \gets \phi$
  \While{$V != \phi$}
  \State Pick any vertex $v$ from $G$ 
  \If {$degree(v) <= n^{1/k}$}
  \State Add all edges incident on $v$ to $E_s$
  \State Remove $v$ and all edges incident on $v$ from $G$
  \Else
  \State Do a BFS from $v$ in graph $G$ till a depth of $k-1$.  
  \State Remove all the non-tree edges (in the formed $k-1$ levels) from $G$
  \State Call this formed tree of depth $k-1$ as $cluster$. 
  \State For all $v \not\in cluster$ retain just one edge with the cluster and remove all other edges from $G$
  \State Add all the tree(cluster) edges along with the edges incident on the cluster to $E_s$
  \State Remove $cluster$ and all edges incident on $cluster$ from $G$
  \EndIf
  \EndWhile
  \State return $Es$
  \EndProcedure
\end{algorithmic} 
\subsection{Justifications}
\subsubsection{Retaining just one edge with the cluster for any $v \not\in cluster$ is sufficient}
Let $v$ be the root of the $cluster$ being discussed. Let $u \not \in cluster$ be the vertex outside cluster who has edges to both $x \in cluster $ and $y \in cluster$. Let us consider what happens when we remove say the edge $(u,y)$. We know $v$ being the root of the BFS tree, is connected to both $x$ and $y$. As the depth of the BFS tree being considered is $k-1$, the maximum path length between $v$ and $x$(or $y$) is $k-1$. This means there is a path between $x$ and $y$ via $v$ that has a maximum length of $2(k-1)$. Though we have removed the edge $(u,y)$, $u$ and $y$ are still connected by the path $(u,x)$, then $x$ to $y$ via $v$. The maximum length of this path between $u$ and $y$ is hence, $2k-1$, satisfying the requirement asked for in the question. This explains why retaining just one edge with the cluster for any $v \not\in cluster$ is sufficient.
\subsubsection{Non-Tree edges need not be retained}
As within the tree any two vertices are always connected via a path whose length $\leq 2k-1$, there is no need to retain non-tree edges.

\subsection{Proving $|E_s| = O(n^{1+1/k}) $}
\begin{itemize}
\item If $degree(v) <= n^{1/k}$ then, we add atmost $n^{1/k}$ edges to $E_s$ for the single vertex $v$.
\item If $degree(v) > n^{1/k}$ then, we add atmost $O(n)$ edges to $E_s$ for a $cluster$ of atleast $n^{1/k}$ vertices.
\item Worst case $|E_s|  =  O(n^{1+1/k})$ 
\end{itemize}
\subsection{Time Complexity}
The overall algorithm accesses an edge exactly for O(1) times, because in any iteration of the while-loop the edge getting accessed is being removed off from $G$ and hence, it is guaranteed that no edge is being accessed in two different iterations. Hence, the time complexity is $O(m+n)$.    
\end{document}
